# -*- coding: utf-8 -*-
"""Bank Marketing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bQ9zEox9LctoSBUzTf2Hv9f6kXU3uZGX
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import pandas as pd
import numpy as np
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

df=pd.read_csv(r"/content/sample_data/bank.csv")
df.info()
df.describe()

# One-Hot Encoding for non-binary categorical columns
categorical_columns = ['job', 'marital', 'education', 'contact', 'month', 'poutcome']
df1 = pd.get_dummies(df, columns=categorical_columns, drop_first=True)

# Label Encoding for binary columns
binary_columns = {'default': {'no': 0, 'yes': 1},
                  'housing': {'no': 0, 'yes': 1},
                  'loan': {'no': 0, 'yes': 1},
                  'y': {'no': 0, 'yes': 1}}  # Target variable

# Replace the values with 0 and 1
df1.replace(binary_columns, inplace=True)

# Check the transformed dataset
df1.head()

# Create the countplot for the 'y' column (assuming 'y' is the target column)
sns.countplot(x='y', data=df1,  edgecolor='black')

# Add labels and title
plt.title('Count of Target Variable')
plt.xlabel('Target (y)')
plt.ylabel('Count')
# Show the plot
plt.show()

# Plotting job distribution
sns.countplot(y='job', data=df, order=df['job'].value_counts().index,  edgecolor='black')
plt.title('Job Distribution of Clients')
plt.show()

# Plotting marital status distribution
sns.countplot(x='marital', data=df,  edgecolor='black')
plt.title('Marital Status Distribution of Clients')
plt.show()

# Plotting education distribution
sns.countplot(x='education', data=df, edgecolor='black')
plt.title('Education Level Distribution of Clients')
plt.show()

# Age distribution
plt.hist(df['age'], bins=20, edgecolor='black')
plt.title('Age Distribution of Clients')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()

# Balance distribution
plt.hist(df['balance'], bins=20, edgecolor='black')
plt.title('Balance Distribution of Clients')
plt.xlabel('Balance')
plt.ylabel('Frequency')
plt.show()


# how the poutcome (outcome of the previous campaign) correlates with the client's subscription to the term deposit.
sns.barplot(x='poutcome', y='y', data=df,edgecolor='black' )
plt.title('Subscription Outcome by Previous Campaign Result')
plt.show()

#Identify the variables
X=df1.drop(columns=["y"],axis=1).astype(np.float32).values
y=df1["y"].astype(np.int32).values

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the numerical features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Define the model
model=Sequential()

#add layers
model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(32,activation='relu'))
model.add(Dense(16,activation='relu'))
#output layer
model.add(Dense(1, activation="sigmoid"))

#compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=["accuracy"])
# Define early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5)

#train the model
model.fit(X_train,y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])

#predictions
# Evaluate the model
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test accuracy: {test_acc}")


data=pd.read_csv("/content/sample_data/sample_data (1).csv")
# Preprocess data - Example: Replace boolean values with integers
data.replace({True: 1, False: 0}, inplace=True)

# Standardize the sample data
X_test= scaler.transform(X_test)

X_test = data.values.astype(np.float32)
# Perform predictions
predicted = model.predict(X_test)

# Since it's a binary classification, use a threshold of 0.5
predicted_class = (predicted > 0.5).astype(int)
print(f"Predicted Class: {predicted_class[0][0]}")